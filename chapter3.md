# Chapter 3: 持久化存储架构

在构建高性能搜索引擎时，持久化存储架构是决定系统吞吐量、延迟和可扩展性的关键因素。本章深入探讨如何设计一个能够支撑十亿级文档、每秒数万次查询的存储系统。我们将重点分析 LSM-tree 架构在搜索引擎场景下的应用，探讨各种压缩算法的选择依据，理解段合并策略的权衡，以及设计高效的内存管理与缓存系统。通过 OCaml 类型系统，我们将清晰地定义各个存储组件的接口，帮助读者理解存储层与索引层、查询层的交互关系。

## 3.1 LSM-tree 的设计原理与接口

Log-Structured Merge-tree (LSM-tree) 是现代搜索引擎存储层的核心数据结构，它通过将随机写转换为顺序写来优化写入性能，这对于需要频繁更新索引的搜索系统至关重要。

### 3.1.1 LSM-tree 基本概念与写优化特性

LSM-tree 的核心思想是将写操作分离到内存和磁盘的不同层级：

1. **写入路径优化**：所有写操作首先进入内存中的可变结构（MemTable），当 MemTable 达到阈值后，转换为不可变的 SSTable 并刷写到磁盘。这种设计将随机写转换为批量顺序写，显著提升了写入吞吐量。

2. **多层结构设计**：磁盘上的 SSTable 组织成多个层级（L0, L1, L2...），每层的大小按指数增长。这种分层设计允许系统在写入性能和读取性能之间进行灵活权衡。

3. **延迟合并策略**：通过后台的异步合并过程，系统可以在不影响前台写入的情况下，逐步整理数据，减少读取时需要检查的文件数量。

### 3.1.2 内存组件 (MemTable) 与磁盘组件 (SSTable) 的设计

**MemTable 设计考虑**：

MemTable 作为写入缓冲区，其数据结构选择直接影响写入性能和内存效率：

- **跳表实现**：提供 O(log n) 的插入和查找复杂度，实现简单且并发友好
- **B+ 树变体**：更好的缓存局部性，适合范围查询密集的场景
- **哈希表 + 有序链表**：结合快速点查询和顺序遍历能力

关键设计参数：
- MemTable 大小阈值（通常 64MB-256MB）
- 写入并发控制机制
- 内存分配策略（预分配 vs. 动态增长）

**SSTable 格式设计**：

SSTable (Sorted String Table) 是磁盘上的不可变文件，其格式设计影响存储效率和读取性能：

```
SSTable 文件结构：
[数据块 1][数据块 2]...[数据块 N][元数据块][索引块][布隆过滤器][文件尾部]
```

关键组件：
- **数据块**：存储键值对，通常 4KB-64KB，支持压缩
- **索引块**：稀疏索引，加速定位数据块
- **布隆过滤器**：快速判断键是否存在，减少无效磁盘访问
- **元数据**：统计信息、压缩算法标识、版本信息等

### 3.1.3 Write-Ahead Log (WAL) 的作用与实现

WAL 是保证数据持久性的关键机制：

1. **崩溃恢复**：通过重放 WAL，可以恢复尚未刷写到磁盘的 MemTable 数据
2. **顺序写入**：WAL 的追加写入模式与 LSM-tree 的设计理念一致
3. **批量提交**：支持将多个写操作打包成一个 WAL 记录，提高效率

WAL 设计要点：
- **记录格式**：包含序列号、操作类型、键值数据、校验和
- **同步策略**：每次写入同步 vs. 批量同步的权衡
- **日志回收**：当对应的 MemTable 刷写完成后，相关 WAL 可以删除

### 3.1.4 读写路径的详细分析

**写入路径**：
1. 写请求首先写入 WAL（可选同步）
2. 数据插入当前活跃的 MemTable
3. 当 MemTable 满时，转换为不可变 MemTable
4. 后台线程将不可变 MemTable 刷写为 SSTable
5. 更新元数据，将新 SSTable 加入 L0 层

**读取路径**：
1. 首先检查活跃 MemTable
2. 检查不可变 MemTable（如果存在）
3. 按层级顺序检查 SSTable（利用布隆过滤器加速）
4. 在每层中，可能需要检查多个 SSTable
5. 合并多个源的结果，返回最新版本

优化技术：
- **并行查找**：同时搜索多个 SSTable
- **缓存命中**：块缓存避免重复磁盘访问
- **预取策略**：基于访问模式的智能预读

### 3.1.5 OCaml 类型系统定义 LSM-tree 接口

使用 OCaml 的模块系统，我们可以清晰地定义 LSM-tree 的接口：

```ocaml
module type LSM_TREE = sig
  type t
  type key = string
  type value = string
  type write_options = {
    sync: bool;  (* 是否同步 WAL *)
    batch_size: int option;  (* 批量写入大小 *)
  }
  
  type read_options = {
    snapshot: int option;  (* 读取特定版本 *)
    fill_cache: bool;  (* 是否填充块缓存 *)
  }
  
  (* 基本操作 *)
  val create : config -> t
  val put : t -> key -> value -> write_options -> unit
  val get : t -> key -> read_options -> value option
  val delete : t -> key -> write_options -> unit
  val batch : t -> (key * value option) list -> write_options -> unit
  
  (* 迭代器接口 *)
  module Iterator : sig
    type iterator
    val create : t -> key option -> key option -> iterator
    val next : iterator -> (key * value) option
    val seek : iterator -> key -> unit
  end
  
  (* 管理接口 *)
  val flush : t -> unit
  val compact : t -> int -> int -> unit  (* 手动触发合并 *)
  val stats : t -> statistics
end
```

这个接口设计体现了几个关键原则：
- **操作原子性**：每个操作都是原子的
- **配置灵活性**：通过 options 参数提供细粒度控制
- **迭代器模式**：支持高效的范围扫描
- **管理能力**：暴露必要的维护操作

## 3.2 索引压缩算法的选择依据

在搜索引擎的存储层，压缩不仅能够减少磁盘空间占用，更重要的是能够减少 I/O 传输量，从而提升查询性能。选择合适的压缩算法需要在压缩率、压缩/解压速度、随机访问能力等多个维度进行权衡。

### 3.2.1 压缩算法分类

搜索引擎存储层常用的压缩技术可以分为以下几类：

**1. 字典编码（Dictionary Encoding）**

适用于高重复率的数据，如文档中的词项：
- 构建值到整数的映射表
- 存储整数而非原始字符串
- 特别适合 categorical 数据和短字符串

优势：高压缩率，支持快速相等性比较
劣势：需要维护字典，不适合基数很高的数据

**2. 差分编码（Delta Encoding）**

适用于排序后的整数序列，如文档 ID 列表：
- 存储相邻值的差值而非绝对值
- 配合变长编码使用效果更佳
- 支持流式解码

优势：对递增序列压缩效果极佳
劣势：不支持随机访问，解码需要从头开始

**3. 位图压缩（Bitmap Compression）**

适用于稀疏或密集的布尔数据：
- Roaring Bitmaps：混合使用数组、位图和行程编码
- WAH (Word Aligned Hybrid)：字对齐的混合编码
- EWAH：WAH 的增强版本

优势：支持快速的集合操作（AND、OR、XOR）
劣势：对非布尔数据需要预处理

### 3.2.2 倒排列表压缩技术详解

倒排列表是搜索引擎的核心数据结构，其压缩算法的选择直接影响查询性能：

**VByte (Variable Byte Encoding)**

最简单的变长编码方案：
- 每个字节的最高位作为延续标志
- 7 位用于存储数据
- 实现简单，解码快速

编码示例：
- 127 → 0x7F (1 字节)
- 128 → 0x80 0x01 (2 字节)
- 16384 → 0x80 0x80 0x01 (3 字节)

**Simple9**

将多个小整数打包到一个 32 位字中：
- 4 位选择器 + 28 位数据
- 支持多种打包方案（28×1位, 14×2位, 9×3位等）
- 批量解码提高效率

优势：更好的压缩率，SIMD 友好
劣势：实现复杂度较高

**PForDelta (Patched Frame of Reference)**

结合了多种技术的高级压缩方案：
1. Delta 编码：存储差值
2. Frame of Reference：每块选择合适的位宽
3. Patching：异常值单独存储

关键参数：
- 块大小（通常 128 或 256）
- 异常值比例阈值（通常 10%）
- 位宽选择策略

### 3.2.3 压缩率与解压速度的权衡

选择压缩算法时需要考虑的关键指标：

**压缩率 (Compression Ratio)**
- 定义：原始大小 / 压缩后大小
- 影响因素：数据分布、算法复杂度、块大小
- 典型值：倒排列表 3-10x，文本数据 2-4x

**解压速度 (Decompression Speed)**
- 单位：GB/s 或 整数个数/秒
- 关键场景：查询时实时解压
- 优化技术：SIMD 指令、批量处理、预取

**压缩速度 (Compression Speed)**
- 相对不太关键（离线构建索引）
- 但影响索引更新的实时性
- 需要考虑 CPU 资源消耗

平衡策略：
1. **查询密集型**：优先选择解压快的算法（如 VByte）
2. **存储受限**：选择压缩率高的算法（如 PForDelta）
3. **混合负载**：分层压缩，热数据用快速算法，冷数据用高压缩算法

### 3.2.4 针对不同数据特征的算法选择

**文档 ID 列表**
- 特征：单调递增，差值较小
- 推荐：Delta + VByte 或 PForDelta
- 优化：分组压缩支持 skip

**词频数据**
- 特征：小整数，幂律分布
- 推荐：Simple9 或直接 VByte
- 考虑：Unary 编码 for very small values

**位置信息**
- 特征：文档内递增，跨文档重置
- 推荐：分文档压缩，Delta + VByte
- 优化：考虑相对位置编码

**文本内容**
- 特征：自然语言，高冗余
- 推荐：LZ4（快速）或 Zstd（高压缩）
- 权衡：块大小影响随机访问

### 3.2.5 压缩块大小的设计考虑

块大小是影响压缩系统性能的关键参数：

**小块（1-4 KB）**
- 优势：细粒度访问，减少读放大
- 劣势：压缩率降低，元数据开销大
- 适用：随机访问频繁的场景

**大块（16-64 KB）**
- 优势：更好的压缩率，顺序读取效率高
- 劣势：随机访问开销大，内存占用多
- 适用：批量扫描为主的场景

**自适应块大小**
- 根据数据特征动态调整
- 热点数据用小块，冷数据用大块
- 实现复杂但效果最优

设计建议：
1. 与存储设备特性匹配（SSD 页大小）
2. 考虑 CPU 缓存大小
3. 平衡压缩率和访问粒度
4. 支持块级别的并行处理

## 3.3 段合并策略的权衡分析

段合并（Compaction）是 LSM-tree 维持读取性能的核心机制。不同的合并策略在写放大、读放大和空间放大之间有着不同的权衡。理解这些权衡对于设计高效的搜索引擎存储系统至关重要。

### 3.3.1 Leveled Compaction vs. Size-Tiered Compaction

**Size-Tiered Compaction (STCS)**

STCS 是最简单直观的合并策略：
- 将大小相近的 SSTable 合并在一起
- 通常当某一"层"积累了 N 个文件时触发合并（N 通常为 4-10）
- 合并后产生一个更大的文件，进入下一层

优势：
- 写放大较低（每层只合并一次）
- 实现简单，易于理解和调试
- 适合写入密集的工作负载

劣势：
- 空间放大严重（最坏情况 2× 数据大小）
- 读放大较高（可能需要检查多个文件）
- 临时空间需求大（合并时需要额外空间）

**Leveled Compaction**

Leveled Compaction 将数据组织成多个不重叠的层级：
- L0：直接从 MemTable 刷写，可能有重叠
- L1 及以上：每层内部文件的键范围不重叠
- 每层大小是上一层的 10 倍（可配置）

合并过程：
1. 从 Li 选择一个文件
2. 找出 Li+1 中所有重叠的文件
3. 合并并重新分割，写回 Li+1

优势：
- 空间放大小（通常 1.1× 数据大小）
- 读放大有保证（每层最多一个文件）
- 更可预测的性能

劣势：
- 写放大高（数据可能被重写多次）
- 实现复杂，需要精确的边界管理
- 可能产生写入抖动

### 3.3.2 写放大与读放大的权衡

**写放大（Write Amplification）**

定义：实际写入的数据量 / 用户写入的数据量

影响因素：
- 合并策略：Leveled > STCS
- 层数：更多层级意味着更高的写放大
- 数据模式：更新频繁的热点数据写放大更严重

计算模型：
- STCS：约 O(log N) 其中 N 是层数
- Leveled：约 O(L × F) 其中 L 是层数，F 是扇出因子

**读放大（Read Amplification）**

定义：读取操作需要访问的文件数

组成部分：
1. 搜索多个层级
2. 每层可能有多个候选文件
3. 假阳性（布隆过滤器的误判）

优化技术：
- 布隆过滤器：减少无效的文件访问
- 层级缓存：缓存上层的热点数据
- 并行搜索：同时查询多个文件

### 3.3.3 空间放大的控制策略

空间放大是指存储系统实际占用的空间与逻辑数据大小的比值：

**产生原因**：
1. 过期版本：已删除或更新的旧数据
2. 删除墓碑：标记删除的特殊记录
3. 碎片化：部分填充的块
4. 临时文件：合并过程中的中间数据

**控制策略**：

1. **激进的垃圾回收**
   - 更频繁的合并，及时清理过期数据
   - 代价：增加写放大和 CPU 使用

2. **分层存储**
   - 热数据使用低压缩、快速访问的格式
   - 冷数据使用高压缩、节省空间的格式
   - 通过访问频率自动迁移

3. **智能文件选择**
   - 优先合并垃圾比例高的文件
   - 使用统计信息指导合并决策
   - 避免合并刚写入的文件

4. **增量合并**
   - 将大的合并任务分解成小步骤
   - 减少峰值空间需求
   - 提供更平滑的性能

### 3.3.4 合并触发条件与调度算法

**触发条件设计**：

1. **基于大小的触发**
   ```
   if level[i].size() > level[i].max_size:
     trigger_compaction(level[i])
   ```

2. **基于文件数的触发**
   ```
   if level[i].file_count() > max_files_per_level:
     trigger_compaction(level[i])
   ```

3. **基于年龄的触发**
   - 防止数据长期不被合并
   - 确保删除墓碑最终被清理

4. **基于统计的触发**
   - 监控读放大指标
   - 垃圾比例超过阈值
   - 查询延迟恶化

**调度算法**：

1. **优先级队列**
   - 根据紧急程度排序合并任务
   - 考虑因素：层级、大小、垃圾比例

2. **资源感知调度**
   - 监控 I/O 带宽使用
   - 在低负载时期执行大合并
   - 限制并发合并数量

3. **增量执行**
   - 将大合并分解为小任务
   - 每个任务处理固定大小的数据
   - 支持暂停和恢复

### 3.3.5 热数据识别与分层存储

识别和优化热数据访问是提升存储系统性能的关键：

**热数据识别技术**：

1. **访问计数器**
   - 每个 SSTable 维护访问统计
   - 定期衰减避免历史数据影响
   - 开销小但精度有限

2. **采样统计**
   - 对部分请求进行详细追踪
   - 推断整体访问模式
   - 平衡开销和准确性

3. **机器学习预测**
   - 基于历史模式预测未来访问
   - 考虑时间、键范围等特征
   - 适合有规律的访问模式

**分层存储架构**：

```
热数据层（NVMe SSD）
├── 最近写入的数据
├── 高频访问的索引
└── 关键元数据

温数据层（SATA SSD）  
├── 中等访问频率数据
└── 较早的版本数据

冷数据层（HDD/对象存储）
├── 归档数据
├── 备份快照
└── 合规保留数据
```

**数据迁移策略**：

1. **被动迁移**：合并时根据访问频率决定目标层
2. **主动迁移**：定期扫描并移动数据
3. **混合策略**：结合被动和主动，平衡开销

关键设计考虑：
- 迁移粒度（文件级 vs 块级）
- 迁移阈值的动态调整
- 避免频繁迁移（迟滞策略）
- 迁移对前台操作的影响控制
